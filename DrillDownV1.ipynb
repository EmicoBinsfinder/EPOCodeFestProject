{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOW9duHkJ4fbHMqhUpXgcTq",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmicoBinsfinder/EPOCodeFestProject/blob/main/DrillDownV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "AwZLm-jWYBaO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Configure OpenAI API key\n",
        "\n",
        "# access your OpenAI API key\n",
        "\n",
        "# installing llmx first isn't necessary but avoids a confusing error when installing openai\n",
        "!pip install -q llmx\n",
        "!pip install -q openai\n",
        "from openai import OpenAI\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "openai_api_secret_name = 'Test'\n",
        "## @param {type: \"string\"}\n",
        "\n",
        "try:\n",
        "  OPENAI_API_KEY=userdata.get(openai_api_secret_name)\n",
        "  OpenAIclient = OpenAI(\n",
        "    api_key=OPENAI_API_KEY\n",
        "  )\n",
        "except userdata.SecretNotFoundError as e:\n",
        "   print(f'''Secret not found\\n\\nThis expects you to create a secret named {openai_api_secret_name} in Colab\\n\\nVisit https://platform.openai.com/api-keys to create an API key\\n\\nStore that in the secrets section on the left side of the notebook (key icon)\\n\\nName the secret {openai_api_secret_name}''')\n",
        "   raise e\n",
        "except userdata.NotebookAccessError as e:\n",
        "  print(f'''You need to grant this notebook access to the {openai_api_secret_name} secret in order for the notebook to access Gemini on your behalf.''')\n",
        "  raise e\n",
        "except Exception as e:\n",
        "  # unknown error\n",
        "  print(f\"There was an unknown error. Ensure you have a secret {openai_api_secret_name} stored in Colab and it's a valid key from https://platform.openai.com/api-keys\")\n",
        "  raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### System Setup"
      ],
      "metadata": {
        "id": "VDvlToWKzTLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !pip install gradio\n",
        "# !pip install elasticsearch\n",
        "# !pip install langchain"
      ],
      "metadata": {
        "id": "efCLY8SmYC9V"
      },
      "execution_count": 119,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## IMPORTING REQUIRED PYTHON PACKAGES ##########\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import math\n",
        "import time\n",
        "import csv\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "import gradio\n",
        "import os\n",
        "import pprint\n",
        "from elasticsearch import Elasticsearch\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ElasticsearchChatMessageHistory\n",
        "from uuid import uuid4\n",
        "import os, sys\n",
        "import json, csv"
      ],
      "metadata": {
        "id": "7mbvLF34rrp2",
        "outputId": "5b289c57-dd19-4842-ba0b-300ca0830446",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 120,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get my os environment\n",
        "os.environ['ELASTICSEARCH_PASSWORD'] = 'l0ng-r4nd0m-p@ssw0rd'\n",
        "pwd = os.environ[\"ELASTICSEARCH_PASSWORD\"]\n",
        "\n",
        "# Password for the 'elastic' user generated by Elasticsearch\n",
        "ELASTIC_PASSWORD = pwd\n",
        "\n",
        "# Found in the 'Manage Deployment' page\n",
        "CLOUD_ID = \"http://AnkarDev-Elasticsearch-1891076460.eu-west-2.elb.amazonaws.com:9200\"\n",
        "\n",
        "# Create the client instance\n",
        "client = Elasticsearch(\n",
        "    CLOUD_ID,\n",
        "    basic_auth=(\"eogbomo\", ELASTIC_PASSWORD),\n",
        "    verify_certs=False\n",
        ")"
      ],
      "metadata": {
        "id": "L8N-BJExLO6b"
      },
      "execution_count": 121,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Gradio App"
      ],
      "metadata": {
        "id": "RI26vOs9AFaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def loadprevresponses(QueryID):\n",
        "  try:\n",
        "    with open (f'{QueryID}_responses.json', 'r+') as file:\n",
        "      try:\n",
        "        data = json.load(file)\n",
        "        datastr = list(data.values())\n",
        "        datastr = ', '.join(datastr)\n",
        "      except:\n",
        "        print('Error loading responses')\n",
        "        data = {}\n",
        "  except FileNotFoundError:\n",
        "    with open (f'{QueryID}_responses.json', 'w') as file:\n",
        "      data = {}\n",
        "      datastr = ''\n",
        "      json.dump(data, file)\n",
        "  return data, datastr\n",
        "\n",
        "def saveresponse(input, QueryID):\n",
        "  history, historystr = loadprevresponses(QueryID)\n",
        "\n",
        "  history[f'Input{len(history)+1}'] = input\n",
        "  with open (f'{QueryID}_responses.json', 'r+') as file:\n",
        "    json.dump(history, file)\n"
      ],
      "metadata": {
        "id": "pxLEKRmTpClm"
      },
      "execution_count": 122,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def DrillDown(input, QueryID):\n",
        "\n",
        "  history, historystr = loadprevresponses(QueryID)\n",
        "  saveresponse(input, QueryID)\n",
        "\n",
        "  input += historystr\n",
        "\n",
        "  prompt = \"\"\"You are an expert in translating natural language queries about patents into ElasticSearch Queries.\n",
        "    Given a user input, create an Elasticsearch query enabling the user to return as many relevant patents as possible when querying in Elastic\n",
        "\n",
        "    input: {input}\n",
        "\n",
        "    \"\"\".format(input=input)\n",
        "\n",
        "  additional_prompt=\"\"\"\n",
        "    Instructions:\n",
        "    1. Generate Elasticsearch queries based on the provided natural language queries.\n",
        "    2. Only use fields present in the mapping. If the user is asking about a field that is not in the mapping ignore it.\n",
        "    3. Ensure that the generated queries follow Elasticsearch's query DSL syntax and structure.\n",
        "    4. You can correct or reformulate the user's query if it has errors.\n",
        "    5. Return all fields in your response when applicable.\n",
        "    6. Make sure that the query only performs full text search when applicable i.e. don't use keyword search\n",
        "    7. When returning the json portion of the answer, compress the json output removing spaces. Remove any mention of json in the output or triple backtick sand make sure that it's valid.\n",
        "    8. Ensure that as many aspects of the user input are captired as possible\n",
        "\n",
        "    Examples of expected behavior:\n",
        "    Natural Language Query: \"What is the title of the most recent Apple patent\"\n",
        "    Expected Elasticsearch Query:\n",
        "    {\n",
        "      \"size\": 1,\n",
        "      \"sort\": [\n",
        "        {\n",
        "          \"publicationDate\": {\n",
        "            \"order\": \"desc\"\n",
        "          }\n",
        "        }\n",
        "      ],\n",
        "      \"query\": {\n",
        "        \"bool\": {\n",
        "          \"must\": [\n",
        "            {\n",
        "              \"match\": {\n",
        "                \"applicants\": \"apple\"\n",
        "              }\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "    Natural Language Query: \"What are the most recent methods to deal with cell group failure?\"\n",
        "    Expected Elasticsearch Query:\n",
        "    {\n",
        "      \"query\": {\n",
        "        \"bool\": {\n",
        "          \"must\": [\n",
        "            {\n",
        "              \"bool\": {\n",
        "                \"should\": [\n",
        "                  {\n",
        "                    \"match\": {\n",
        "                      \"patentTitle\": \"cell group failure\"\n",
        "                    }\n",
        "                  },\n",
        "                  {\n",
        "                    \"match\": {\n",
        "                      \"patentAbstract\": \"cell group failure\"\n",
        "                    }\n",
        "                  },\n",
        "                  {\n",
        "                    \"match\": {\n",
        "                      \"claims.claimText\": \"cell group failure\"\n",
        "                    }\n",
        "                  },\n",
        "                  {\n",
        "                    \"match\": {\n",
        "                      \"patentDescription\": \"cell group failure\"\n",
        "                    }\n",
        "                  }\n",
        "                ]\n",
        "              }\n",
        "            }\n",
        "          ],\n",
        "          \"filter\": [\n",
        "            {\n",
        "              \"range\": {\n",
        "                \"publicationDate\": {\n",
        "                  \"gte\": \"now-5y/d\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      },\n",
        "      \"_source\": [\"*\"]\n",
        "    }\"\"\"\n",
        "  prompt += additional_prompt\n",
        "\n",
        "  completion = OpenAIclient.chat.completions.create(\n",
        "  model=\"gpt-4-0125-preview\",\n",
        "  messages=[\n",
        "  {\"role\": \"user\", \"content\": f'Your function is that of a bot optimised for summarising patent text. Answer the following query as accurately as possible based on your function {prompt}'}\n",
        "  ]\n",
        "  )\n",
        "  response = completion.choices[0].message.content\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "UUiITGnU3I0W"
      },
      "execution_count": 123,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs = gradio.Textbox(lines=7, label=\"Generate Queries for use with Elastic Search, allowing for search refinement\")\n",
        "# outputs = gradio.Textbox(label=\"Reply\")\n",
        "\n",
        "# gradio.Interface(fn=DrillDown, inputs=inputs, outputs=outputs, title=\"Patent DrillDown Prototype\",\n",
        "#              theme=\"compact\").launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "s5xDQySpeTZF"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load in and prepare test dataset"
      ],
      "metadata": {
        "id": "loIWwyaHZ86y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Queries = pd.read_csv('/content/Valeo_Queries_Testing.csv')\n",
        "\n",
        "Queries_List = Queries['Query'].tolist()\n",
        "\n",
        "## Add IDs to Queries for tracking later on\n",
        "\n",
        "ID_Queries_List = []\n",
        "for index, query in enumerate(Queries_List):\n",
        "  QueryID = f'Query_{index}'\n",
        "  query += f'////{QueryID}'\n",
        "  ID_Queries_List.append(query)"
      ],
      "metadata": {
        "id": "bz21BfpEWeM5"
      },
      "execution_count": 125,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define function to simulate drill down workflow"
      ],
      "metadata": {
        "id": "ZmKh0K1oaA3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def DrillDownQueryGenerator(Initial_Query):\n",
        "\n",
        "  prompt = f\"\"\"\n",
        "You are an expert in mimicking the behaviour of a patent professional using an AI powered patent search tool.\n",
        "Based on the provided initial query delimited by triple backticks marks ```Initial User Query```,\n",
        "provided a list of up to 10 sequential queries that could both narrow and broaden the scope of the search.\n",
        "Return the list of queries in the format of a Python list.\n",
        "\n",
        "When creating the list of queries, strictly follow the list of numbered instructions below:\n",
        "\n",
        "1. When creating queries that vary the scope of the initial search\n",
        "2. Ensure that all generated follow up queries are relevant to the initial provided query.\n",
        "3. When creating a narrowing query, define the scope of the query such that it focusses on a more specific, relevant technology or technical area (example: A car panel made from metal > a car panel made of steel).\n",
        "4. When creating a broadening query, define the scope of the query such that it focusses on a less specific, relevant technology or technical area (example: patents about batteries cooled using a heat sink > patents about battery cooling).\n",
        "5. When receiving initial queries that include dates, make sure to have some follow up queries with different dates, but not all (example, Patent with priority date before 2012 > Now look at with priority date before 2009)\n",
        "6. When receiving initial queries with several aspects, start by generating queries that are likely to broaden the scope of the search.\n",
        "7. When receiving initial queries that are quite broad and ambiguous, start by generating queries that are likely to narrow the scope of the search.\n",
        "8. Return only the list of queries in list form, do not return anything outside of the list with limits []\n",
        "9. Make sure to use the word 'narrow' or 'broaden' in the query depending on if it's meant to broaden or narrow the scope of the search\n",
        "10. Mix up the frequency and order of broadening and narrowing queries\n",
        "11. Once you have created the list, double check it to see if the you are returning solely a list, changing the output if it is not just a list.\n",
        "12. Ensure that you are not returning the initial query\n",
        "\n",
        "```{Initial_Query}```\n",
        "\n",
        "Example input: Patents Owned by Valeo\n",
        "\n",
        "Example output:\n",
        "[\n",
        "\"Now broaden the search to include patents owned by other major automotive suppliers\",\n",
        "\"Now focus specifically on patents owned by Valeo related to automotive lighting systems\",\n",
        "\"Now narrow the search to patents owned by Valeo related to autonomous driving technology\",\n",
        "\"Now include patents owned by Valeo and its subsidiaries\",\n",
        "\"Now broaden the search to include patents owned by Valeo related to climate control systems\",\n",
        "\"Now narrow the search to patents owned by Valeo filed within the last 5 years\",\n",
        "\"Now include patents owned by other companies in the automotive industry\",\n",
        "\"Now narrow the search to patents owned by Valeo related to vehicle safety systems\",\n",
        "\"Now broaden the search to include patents owned by Valeo related to automotive electronics\",\n",
        "\"Now exclude patents owned by Valeo's competitors\"\n",
        "]\n",
        "\n",
        "\"\"\"\n",
        "\n",
        "  completion = OpenAIclient.chat.completions.create(\n",
        "  model=\"gpt-4-0125-preview\",\n",
        "  messages=[\n",
        "  {\"role\": \"user\", \"content\": f'Your function is that of a bot optimised for summarising patent text. Answer the following query as accurately as possible based on your function {prompt}'}\n",
        "  ]\n",
        "  )\n",
        "  response = completion.choices[0].message.content\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "4bc3Jb-BZ5uT"
      },
      "execution_count": 126,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Iterate through queries in the Valeo CSV"
      ],
      "metadata": {
        "id": "zv1AgrzdlhEX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "for InitialQuery in ID_Queries_List[:2]:\n",
        "  #Retrieve QueryID\n",
        "  QueryID = InitialQuery.split('////')[-1]\n",
        "\n",
        "  print(InitialQuery)\n",
        "  print(QueryID)\n",
        "\n",
        "  #Simulate list of drill down queries\n",
        "  QueryListString = DrillDownQueryGenerator(InitialQuery)\n",
        "\n",
        "  # # Regular expression pattern to extract the list\n",
        "  # pattern = r'\\[([\\s\\S]*?)\\]'\n",
        "\n",
        "  # # Extracting the list using regex\n",
        "  # matches = re.findall(pattern, QueryListString)\n",
        "\n",
        "  # if matches:\n",
        "  #     # Cleaning up the extracted list\n",
        "  #     QueryList = matches[0].strip().split(\"\\n\")[1:-1]\n",
        "  # else:\n",
        "  #     print(\"No list found in the given text.\")\n",
        "\n",
        "  # #Generte Elastic Search query for each stage of drill down workflow\n",
        "  # Query = DrillDown(QueryList[0], QueryID)\n",
        "\n",
        "  try:\n",
        "    resp = client.search(index=\"patents\", body=Query)\n",
        "\n",
        "    NumResponses = len(resp['hits']['hits'])\n",
        "    ValidESQuery = 'Yes'\n",
        "\n",
        "  except Exception as E:\n",
        "    NumResponses = 0\n",
        "    ValidESQuery = 'No'\n",
        "\n",
        ""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YuN68XNQbS8h",
        "outputId": "f594761e-827d-4e9c-d742-33ae357f2394"
      },
      "execution_count": 127,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "heat exchanger, which includes a composite phase-change material////Query_0\n",
            "Query_0\n",
            "Patents comprising an axial fan or a tangential turbomachine////Query_1\n",
            "Query_1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Testing Pipeline"
      ],
      "metadata": {
        "id": "9jaaJdkDmYOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = Query\n",
        "\n",
        "#Need to change so that number of results is not limited, not sure how\n",
        "resp = client.search(index=\"patents\",\n",
        "                     body=Query)\n",
        "\n",
        "# NumResults =\n",
        "for x in resp['hits']['hits']:\n",
        "  print(resp['hits']['hits'])\n",
        "  print(resp['hits']['hits'][0]['_id'])"
      ],
      "metadata": {
        "id": "Q8hePjn5NQ4E",
        "outputId": "51a24181-aa2f-40e9-874a-16c8d659dfbf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 128,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "IOPub data rate exceeded.\n",
            "The notebook server will temporarily stop sending output\n",
            "to the client in order to avoid crashing it.\n",
            "To change this limit, set the config variable\n",
            "`--NotebookApp.iopub_data_rate_limit`.\n",
            "\n",
            "Current values:\n",
            "NotebookApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
            "NotebookApp.rate_limit_window=3.0 (secs)\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "GXl6RQK4WhP5"
      },
      "execution_count": 128,
      "outputs": []
    }
  ]
}