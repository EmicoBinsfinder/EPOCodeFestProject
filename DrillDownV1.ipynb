{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPAZiB/hhRzpR24K9oSIlXN",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmicoBinsfinder/EPOCodeFestProject/blob/main/DrillDownV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "AwZLm-jWYBaO",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "#@title Configure OpenAI API key\n",
        "\n",
        "# access your OpenAI API key\n",
        "\n",
        "# installing llmx first isn't necessary but avoids a confusing error when installing openai\n",
        "!pip install -q llmx\n",
        "!pip install -q openai\n",
        "from openai import OpenAI\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "openai_api_secret_name = 'Test'\n",
        "## @param {type: \"string\"}\n",
        "\n",
        "try:\n",
        "  OPENAI_API_KEY=userdata.get(openai_api_secret_name)\n",
        "  OpenAIclient = OpenAI(\n",
        "    api_key=OPENAI_API_KEY\n",
        "  )\n",
        "except userdata.SecretNotFoundError as e:\n",
        "   print(f'''Secret not found\\n\\nThis expects you to create a secret named {openai_api_secret_name} in Colab\\n\\nVisit https://platform.openai.com/api-keys to create an API key\\n\\nStore that in the secrets section on the left side of the notebook (key icon)\\n\\nName the secret {openai_api_secret_name}''')\n",
        "   raise e\n",
        "except userdata.NotebookAccessError as e:\n",
        "  print(f'''You need to grant this notebook access to the {openai_api_secret_name} secret in order for the notebook to access Gemini on your behalf.''')\n",
        "  raise e\n",
        "except Exception as e:\n",
        "  # unknown error\n",
        "  print(f\"There was an unknown error. Ensure you have a secret {openai_api_secret_name} stored in Colab and it's a valid key from https://platform.openai.com/api-keys\")\n",
        "  raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### System Setup"
      ],
      "metadata": {
        "id": "VDvlToWKzTLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "!pip install elasticsearch\n",
        "!pip install langchain"
      ],
      "metadata": {
        "id": "efCLY8SmYC9V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c07379e3-8d9a-4d76-a3c2-9a903da546a9"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gradio in /usr/local/lib/python3.10/dist-packages (4.22.0)\n",
            "Requirement already satisfied: aiofiles<24.0,>=22.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2.1)\n",
            "Requirement already satisfied: altair<6.0,>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.2.2)\n",
            "Requirement already satisfied: fastapi in /usr/local/lib/python3.10/dist-packages (from gradio) (0.110.0)\n",
            "Requirement already satisfied: ffmpy in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.2)\n",
            "Requirement already satisfied: gradio-client==0.13.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.13.0)\n",
            "Requirement already satisfied: httpx>=0.24.1 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.27.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.20.3)\n",
            "Requirement already satisfied: importlib-resources<7.0,>=1.3 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.3.0)\n",
            "Requirement already satisfied: jinja2<4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.1.3)\n",
            "Requirement already satisfied: markupsafe~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.1.5)\n",
            "Requirement already satisfied: matplotlib~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.7.1)\n",
            "Requirement already satisfied: numpy~=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.25.2)\n",
            "Requirement already satisfied: orjson~=3.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (3.9.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from gradio) (23.2)\n",
            "Requirement already satisfied: pandas<3.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (1.5.3)\n",
            "Requirement already satisfied: pillow<11.0,>=8.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (9.4.0)\n",
            "Requirement already satisfied: pydantic>=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.6.4)\n",
            "Requirement already satisfied: pydub in /usr/local/lib/python3.10/dist-packages (from gradio) (0.25.1)\n",
            "Requirement already satisfied: python-multipart>=0.0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.0.9)\n",
            "Requirement already satisfied: pyyaml<7.0,>=5.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (6.0.1)\n",
            "Requirement already satisfied: ruff>=0.2.2 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.3.3)\n",
            "Requirement already satisfied: semantic-version~=2.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (2.10.0)\n",
            "Requirement already satisfied: tomlkit==0.12.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.12.0)\n",
            "Requirement already satisfied: typer[all]<1.0,>=0.9 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.9.0)\n",
            "Requirement already satisfied: typing-extensions~=4.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (4.10.0)\n",
            "Requirement already satisfied: uvicorn>=0.14.0 in /usr/local/lib/python3.10/dist-packages (from gradio) (0.29.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.13.0->gradio) (2023.6.0)\n",
            "Requirement already satisfied: websockets<12.0,>=10.0 in /usr/local/lib/python3.10/dist-packages (from gradio-client==0.13.0->gradio) (11.0.3)\n",
            "Requirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.4)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6.0,>=4.2.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.0.4)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (3.6)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx>=0.24.1->gradio) (1.3.1)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx>=0.24.1->gradio) (0.14.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (3.13.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.19.3->gradio) (4.66.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.2.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (4.49.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (1.4.5)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (3.1.2)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib~=3.0->gradio) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3.0,>=1.0->gradio) (2023.4)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0->gradio) (2.16.3)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (8.1.7)\n",
            "Requirement already satisfied: colorama<0.5.0,>=0.4.3 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (0.4.6)\n",
            "Requirement already satisfied: shellingham<2.0.0,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (1.5.4)\n",
            "Requirement already satisfied: rich<14.0.0,>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer[all]<1.0,>=0.9->gradio) (13.7.1)\n",
            "Requirement already satisfied: starlette<0.37.0,>=0.36.3 in /usr/local/lib/python3.10/dist-packages (from fastapi->gradio) (0.36.3)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.33.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6.0,>=4.2.0->gradio) (0.18.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib~=3.0->gradio) (1.16.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (2.16.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx>=0.24.1->gradio) (1.2.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->huggingface-hub>=0.19.3->gradio) (2.0.7)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14.0.0,>=10.11.0->typer[all]<1.0,>=0.9->gradio) (0.1.2)\n",
            "Requirement already satisfied: elasticsearch in /usr/local/lib/python3.10/dist-packages (8.12.1)\n",
            "Requirement already satisfied: elastic-transport<9,>=8 in /usr/local/lib/python3.10/dist-packages (from elasticsearch) (8.12.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.26.2 in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2.0.7)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from elastic-transport<9,>=8->elasticsearch) (2024.2.2)\n",
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.12)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.28)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.3)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.4)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.28 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.28)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.31 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.32)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.1)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.31)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.6.4)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: anyio<5,>=3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (3.7.1)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.31->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.9.15)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.3.1)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3->langchain-core<0.2.0,>=0.1.31->langchain) (1.2.0)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "########## IMPORTING REQUIRED PYTHON PACKAGES ##########\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import math\n",
        "import time\n",
        "import csv\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "import gradio\n",
        "import os\n",
        "import pprint\n",
        "from elasticsearch import Elasticsearch\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ElasticsearchChatMessageHistory\n",
        "from uuid import uuid4\n",
        "import os, sys\n",
        "import json, csv"
      ],
      "metadata": {
        "id": "7mbvLF34rrp2",
        "outputId": "3f316126-2a39-4b6e-950f-bee34574bbce",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get my os environment\n",
        "os.environ['ELASTICSEARCH_PASSWORD'] = 'l0ng-r4nd0m-p@ssw0rd'\n",
        "pwd = os.environ[\"ELASTICSEARCH_PASSWORD\"]\n",
        "\n",
        "# Password for the 'elastic' user generated by Elasticsearch\n",
        "ELASTIC_PASSWORD = pwd\n",
        "\n",
        "# Found in the 'Manage Deployment' page\n",
        "CLOUD_ID = \"http://AnkarDev-Elasticsearch-1891076460.eu-west-2.elb.amazonaws.com:9200\"\n",
        "\n",
        "# Create the client instance\n",
        "client = Elasticsearch(\n",
        "    CLOUD_ID,\n",
        "    basic_auth=(\"eogbomo\", ELASTIC_PASSWORD),\n",
        "    verify_certs=False\n",
        ")"
      ],
      "metadata": {
        "id": "L8N-BJExLO6b"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Gradio App"
      ],
      "metadata": {
        "id": "RI26vOs9AFaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_query1 = {\"size\": 1,\"sort\": [{\"publicationDate\": {\"order\": \"desc\"}}],\"query\": {\"bool\": {\"must\": [{\"match\": {\"applicants\": \"apple\"}}]}}}\n",
        "example_query2 = {\"size\": 1,\"sort\": [{\"publicationDate\": {\"order\": \"desc\"}}],\"query\": {\"bool\": {\"must\": [{\"match\": {\"applicants\": \"apple\"}}]}}}"
      ],
      "metadata": {
        "id": "J6Y_FRWeQ478"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadprevresponses():\n",
        "  try:\n",
        "    with open ('responses.json', 'r+') as file:\n",
        "      try:\n",
        "        data = json.load(file)\n",
        "        datastr = list(data.values())\n",
        "        datastr = ', '.join(datastr)\n",
        "      except:\n",
        "        print('Error loading responses')\n",
        "        data = {}\n",
        "  except FileNotFoundError:\n",
        "    with open ('responses.json', 'w') as file:\n",
        "      data = {}\n",
        "      datastr = ''\n",
        "      json.dump(data, file)\n",
        "  return data, datastr\n",
        "\n",
        "data, datastr = loadprevresponses()\n",
        "print(data, datastr)\n",
        "\n",
        "def saveresponse(input):\n",
        "  history, historystr = loadprevresponses()\n",
        "\n",
        "  history[f'Input{len(history)+1}'] = input\n",
        "  with open ('responses.json', 'r+') as file:\n",
        "    json.dump(history, file)\n"
      ],
      "metadata": {
        "id": "pxLEKRmTpClm",
        "outputId": "6331b89f-6c0f-4747-a2e1-3171f822dc08",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{} \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def DrillDown(input):\n",
        "\n",
        "  history, historystr = loadprevresponses()\n",
        "  saveresponse(input)\n",
        "\n",
        "  input += historystr\n",
        "\n",
        "  prompt = \"\"\"You are an expert in translating natural language queries about patents into ElasticSearch Queries.\n",
        "    Given a user input, create an Elasticsearch query enabling the user to return as many relevant patents as possible when querying in Elastic\n",
        "\n",
        "    input: {input}\n",
        "\n",
        "    \"\"\".format(input=input)\n",
        "\n",
        "  additional_prompt=\"\"\"\n",
        "    Instructions:\n",
        "    1. Generate Elasticsearch queries based on the provided natural language queries.\n",
        "    2. Only use fields present in the mapping. If the user is asking about a field that is not in the mapping ignore it.\n",
        "    3. Ensure that the generated queries follow Elasticsearch's query DSL syntax and structure.\n",
        "    4. You can correct or reformulate the user's query if it has errors.\n",
        "    5. Return all fields in your response when applicable.\n",
        "    6. Make sure that the query only performs full text search when applicable i.e. don't use keyword search\n",
        "    7. When returning the json portion of the answer, compress the json output removing spaces. Remove any mention of json in the output or triple backtick sand make sure that it's valid.\n",
        "    8. Ensure that as many aspects of the user input are captired as possible\n",
        "\n",
        "    Examples of expected behavior:\n",
        "    Natural Language Query: \"What is the title of the most recent Apple patent\"\n",
        "    Expected Elasticsearch Query:\n",
        "    {\n",
        "      \"size\": 1,\n",
        "      \"sort\": [\n",
        "        {\n",
        "          \"publicationDate\": {\n",
        "            \"order\": \"desc\"\n",
        "          }\n",
        "        }\n",
        "      ],\n",
        "      \"query\": {\n",
        "        \"bool\": {\n",
        "          \"must\": [\n",
        "            {\n",
        "              \"match\": {\n",
        "                \"applicants\": \"apple\"\n",
        "              }\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "    Natural Language Query: \"What are the most recent methods to deal with cell group failure?\"\n",
        "    Expected Elasticsearch Query:\n",
        "    {\n",
        "      \"query\": {\n",
        "        \"bool\": {\n",
        "          \"must\": [\n",
        "            {\n",
        "              \"bool\": {\n",
        "                \"should\": [\n",
        "                  {\n",
        "                    \"match\": {\n",
        "                      \"patentTitle\": \"cell group failure\"\n",
        "                    }\n",
        "                  },\n",
        "                  {\n",
        "                    \"match\": {\n",
        "                      \"patentAbstract\": \"cell group failure\"\n",
        "                    }\n",
        "                  },\n",
        "                  {\n",
        "                    \"match\": {\n",
        "                      \"claims.claimText\": \"cell group failure\"\n",
        "                    }\n",
        "                  },\n",
        "                  {\n",
        "                    \"match\": {\n",
        "                      \"patentDescription\": \"cell group failure\"\n",
        "                    }\n",
        "                  }\n",
        "                ]\n",
        "              }\n",
        "            }\n",
        "          ],\n",
        "          \"filter\": [\n",
        "            {\n",
        "              \"range\": {\n",
        "                \"publicationDate\": {\n",
        "                  \"gte\": \"now-5y/d\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      },\n",
        "      \"_source\": [\"*\"]\n",
        "    }\"\"\"\n",
        "  prompt += additional_prompt\n",
        "\n",
        "  completion = OpenAIclient.chat.completions.create(\n",
        "  model=\"gpt-4-0125-preview\",\n",
        "  messages=[\n",
        "  {\"role\": \"user\", \"content\": f'Your function is that of a bot optimised for summarising patent text. Answer the following query as accurately as possible based on your function {prompt}'}\n",
        "  ]\n",
        "  )\n",
        "  response = completion.choices[0].message.content\n",
        "\n",
        "  response = '\\n'.join([response, f\"{'#'*120} \\n\"])\n",
        "  response = '\\n'.join([response, f\"History USED TO GENERATE RESPONSE:\\n {history}\"])\n",
        "\n",
        "  return response\n",
        "\n",
        "inputs = gradio.Textbox(lines=7, label=\"Generate Queries for use with Elastic Search, allowing for search refinement\")\n",
        "outputs = gradio.Textbox(label=\"Reply\")\n",
        "\n",
        "gradio.Interface(fn=DrillDown, inputs=inputs, outputs=outputs, title=\"Patent DrillDown Prototype\",\n",
        "             theme=\"compact\").launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "UUiITGnU3I0W",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 715
        },
        "outputId": "a729477f-c8dd-4134-ab60-432d57418506"
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/gradio/blocks.py:580: UserWarning: Cannot load compact. Caught Exception: 404 Client Error: Not Found for url: https://huggingface.co/api/spaces/compact (Request ID: Root=1-65faf2f7-250f028025dde9ce1839444e;6b964c57-dd61-426c-8524-9df1e5a53e64)\n",
            "\n",
            "Sorry, we can't find the page you are looking for.\n",
            "  warnings.warn(f\"Cannot load {theme}. Caught Exception: {str(e)}\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Colab notebook detected. This cell will run indefinitely so that you can see errors and logs. To turn off, set debug=False in launch().\n",
            "Running on public URL: https://d0413c1bc5e5fa2b0e.gradio.live\n",
            "\n",
            "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<div><iframe src=\"https://d0413c1bc5e5fa2b0e.gradio.live\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Keyboard interruption in main thread... closing server.\n",
            "Killing tunnel 127.0.0.1:7860 <> https://d0413c1bc5e5fa2b0e.gradio.live\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": []
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Get search response"
      ],
      "metadata": {
        "id": "9jaaJdkDmYOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = {\n",
        "\"query\":{\n",
        "\"bool\":{\n",
        "\"must\":[\n",
        "{\n",
        "\"bool\":{\n",
        "\"should\":[\n",
        "{\n",
        "\"match\":{\n",
        "\"patentTitle\":\"Aquablade\"\n",
        "}\n",
        "},\n",
        "{\n",
        "\"match\":{\n",
        "\"patentAbstract\":\"liquid passing through the wiper blade\"\n",
        "}\n",
        "},\n",
        "{\n",
        "\"match\":{\n",
        "\"claims.claimText\":\"projected from the blade onto the windshield\"\n",
        "}\n",
        "},\n",
        "{\n",
        "\"match\":{\n",
        "\"patentDescription\":\"Aquablade\"\n",
        "}\n",
        "}\n",
        "]\n",
        "}\n",
        "},\n",
        "{\n",
        "\"term\":{\n",
        "\"jurisdiction\":\"CN\"\n",
        "}\n",
        "}\n",
        "],\n",
        "\"filter\":[\n",
        "{\n",
        "\"terms\":{\n",
        "\"status\":[\"pending\",\"granted\"]\n",
        "}\n",
        "}\n",
        "]\n",
        "}\n",
        "}\n",
        "}\n"
      ],
      "metadata": {
        "id": "otheqsp3mfc3"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resp = client.search(index=\"patents\",\n",
        "                     body=query)\n",
        "\n",
        "print(resp)"
      ],
      "metadata": {
        "id": "Q8hePjn5NQ4E",
        "outputId": "cae23019-fc56-447b-efcd-c3f235418ad0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'took': 1, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 0, 'relation': 'eq'}, 'max_score': None, 'hits': []}}\n"
          ]
        }
      ]
    }
  ]
}