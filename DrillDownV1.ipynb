{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOfSdSrUgH7//NO2p+EZNn+",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmicoBinsfinder/EPOCodeFestProject/blob/main/DrillDownV1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "AwZLm-jWYBaO",
        "cellView": "form",
        "outputId": "b3c3af3c-1636-4923-bb6e-f0252e63366d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m262.9/262.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m11.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m3.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.1/145.1 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "#@title Configure OpenAI API key\n",
        "\n",
        "# access your OpenAI API key\n",
        "\n",
        "# installing llmx first isn't necessary but avoids a confusing error when installing openai\n",
        "!pip install -q llmx\n",
        "!pip install -q openai\n",
        "from openai import OpenAI\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "openai_api_secret_name = 'Test'\n",
        "## @param {type: \"string\"}\n",
        "\n",
        "try:\n",
        "  OPENAI_API_KEY=userdata.get(openai_api_secret_name)\n",
        "  OpenAIclient = OpenAI(\n",
        "    api_key=OPENAI_API_KEY\n",
        "  )\n",
        "except userdata.SecretNotFoundError as e:\n",
        "   print(f'''Secret not found\\n\\nThis expects you to create a secret named {openai_api_secret_name} in Colab\\n\\nVisit https://platform.openai.com/api-keys to create an API key\\n\\nStore that in the secrets section on the left side of the notebook (key icon)\\n\\nName the secret {openai_api_secret_name}''')\n",
        "   raise e\n",
        "except userdata.NotebookAccessError as e:\n",
        "  print(f'''You need to grant this notebook access to the {openai_api_secret_name} secret in order for the notebook to access Gemini on your behalf.''')\n",
        "  raise e\n",
        "except Exception as e:\n",
        "  # unknown error\n",
        "  print(f\"There was an unknown error. Ensure you have a secret {openai_api_secret_name} stored in Colab and it's a valid key from https://platform.openai.com/api-keys\")\n",
        "  raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### System Setup"
      ],
      "metadata": {
        "id": "VDvlToWKzTLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gradio\n",
        "!pip install elasticsearch\n",
        "!pip install langchain"
      ],
      "metadata": {
        "id": "efCLY8SmYC9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## IMPORTING REQUIRED PYTHON PACKAGES ##########\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import math\n",
        "import time\n",
        "import csv\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "import gradio\n",
        "import os\n",
        "import pprint\n",
        "from elasticsearch import Elasticsearch\n",
        "from langchain.llms import OpenAI\n",
        "from langchain.chains import ConversationalRetrievalChain\n",
        "from langchain.memory import ElasticsearchChatMessageHistory\n",
        "from uuid import uuid4\n",
        "import os, sys\n",
        "import json, csv"
      ],
      "metadata": {
        "id": "7mbvLF34rrp2",
        "outputId": "3fda8d52-bdac-4cfc-f88a-55301e7012bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get my os environment\n",
        "os.environ['ELASTICSEARCH_PASSWORD'] = 'l0ng-r4nd0m-p@ssw0rd'\n",
        "pwd = os.environ[\"ELASTICSEARCH_PASSWORD\"]\n",
        "\n",
        "# Password for the 'elastic' user generated by Elasticsearch\n",
        "ELASTIC_PASSWORD = pwd\n",
        "\n",
        "# Found in the 'Manage Deployment' page\n",
        "CLOUD_ID = \"http://AnkarDev-Elasticsearch-1891076460.eu-west-2.elb.amazonaws.com:9200\"\n",
        "\n",
        "# Create the client instance\n",
        "client = Elasticsearch(\n",
        "    CLOUD_ID,\n",
        "    basic_auth=(\"eogbomo\", ELASTIC_PASSWORD),\n",
        "    verify_certs=False\n",
        ")"
      ],
      "metadata": {
        "id": "L8N-BJExLO6b"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Gradio App"
      ],
      "metadata": {
        "id": "RI26vOs9AFaG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_query1 = {\"size\": 1,\"sort\": [{\"publicationDate\": {\"order\": \"desc\"}}],\"query\": {\"bool\": {\"must\": [{\"match\": {\"applicants\": \"apple\"}}]}}}\n",
        "example_query2 = {\"size\": 1,\"sort\": [{\"publicationDate\": {\"order\": \"desc\"}}],\"query\": {\"bool\": {\"must\": [{\"match\": {\"applicants\": \"apple\"}}]}}}"
      ],
      "metadata": {
        "id": "J6Y_FRWeQ478"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loadprevresponses():\n",
        "  try:\n",
        "    with open ('responses.json', 'r+') as file:\n",
        "      try:\n",
        "        data = json.load(file)\n",
        "        datastr = list(data.values())\n",
        "        datastr = ', '.join(datastr)\n",
        "      except:\n",
        "        print('Error loading responses')\n",
        "        data = {}\n",
        "  except FileNotFoundError:\n",
        "    with open ('responses.json', 'w') as file:\n",
        "      data = {}\n",
        "      datastr = ''\n",
        "      json.dump(data, file)\n",
        "  return data, datastr\n",
        "\n",
        "data, datastr = loadprevresponses()\n",
        "print(data, datastr)\n",
        "\n",
        "def saveresponse(input):\n",
        "  history, historystr = loadprevresponses()\n",
        "\n",
        "  history[f'Input{len(history)+1}'] = input\n",
        "  with open ('responses.json', 'r+') as file:\n",
        "    json.dump(history, file)\n"
      ],
      "metadata": {
        "id": "pxLEKRmTpClm",
        "outputId": "dd6463ee-bfac-4fb2-d657-704b69daf18e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{} \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def DrillDown(input):\n",
        "\n",
        "  history, historystr = loadprevresponses()\n",
        "  saveresponse(input)\n",
        "\n",
        "  input += historystr\n",
        "\n",
        "  prompt = \"\"\"You are an expert in translating natural language queries about patents into ElasticSearch Queries.\n",
        "    Given a user input, create an Elasticsearch query enabling the user to return as many relevant patents as possible when querying in Elastic\n",
        "\n",
        "    input: {input}\n",
        "\n",
        "    \"\"\".format(input=input)\n",
        "\n",
        "  additional_prompt=\"\"\"\n",
        "    Instructions:\n",
        "    1. Generate Elasticsearch queries based on the provided natural language queries.\n",
        "    2. Only use fields present in the mapping. If the user is asking about a field that is not in the mapping ignore it.\n",
        "    3. Ensure that the generated queries follow Elasticsearch's query DSL syntax and structure.\n",
        "    4. You can correct or reformulate the user's query if it has errors.\n",
        "    5. Return all fields in your response when applicable.\n",
        "    6. Make sure that the query only performs full text search when applicable i.e. don't use keyword search\n",
        "    7. When returning the json portion of the answer, compress the json output removing spaces. Remove any mention of json in the output or triple backtick sand make sure that it's valid.\n",
        "    8. Ensure that as many aspects of the user input are captired as possible\n",
        "\n",
        "    Examples of expected behavior:\n",
        "    Natural Language Query: \"What is the title of the most recent Apple patent\"\n",
        "    Expected Elasticsearch Query:\n",
        "    {\n",
        "      \"size\": 1,\n",
        "      \"sort\": [\n",
        "        {\n",
        "          \"publicationDate\": {\n",
        "            \"order\": \"desc\"\n",
        "          }\n",
        "        }\n",
        "      ],\n",
        "      \"query\": {\n",
        "        \"bool\": {\n",
        "          \"must\": [\n",
        "            {\n",
        "              \"match\": {\n",
        "                \"applicants\": \"apple\"\n",
        "              }\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      }\n",
        "    }\n",
        "\n",
        "    Natural Language Query: \"What are the most recent methods to deal with cell group failure?\"\n",
        "    Expected Elasticsearch Query:\n",
        "    {\n",
        "      \"query\": {\n",
        "        \"bool\": {\n",
        "          \"must\": [\n",
        "            {\n",
        "              \"bool\": {\n",
        "                \"should\": [\n",
        "                  {\n",
        "                    \"match\": {\n",
        "                      \"patentTitle\": \"cell group failure\"\n",
        "                    }\n",
        "                  },\n",
        "                  {\n",
        "                    \"match\": {\n",
        "                      \"patentAbstract\": \"cell group failure\"\n",
        "                    }\n",
        "                  },\n",
        "                  {\n",
        "                    \"match\": {\n",
        "                      \"claims.claimText\": \"cell group failure\"\n",
        "                    }\n",
        "                  },\n",
        "                  {\n",
        "                    \"match\": {\n",
        "                      \"patentDescription\": \"cell group failure\"\n",
        "                    }\n",
        "                  }\n",
        "                ]\n",
        "              }\n",
        "            }\n",
        "          ],\n",
        "          \"filter\": [\n",
        "            {\n",
        "              \"range\": {\n",
        "                \"publicationDate\": {\n",
        "                  \"gte\": \"now-5y/d\"\n",
        "                }\n",
        "              }\n",
        "            }\n",
        "          ]\n",
        "        }\n",
        "      },\n",
        "      \"_source\": [\"*\"]\n",
        "    }\"\"\"\n",
        "  prompt += additional_prompt\n",
        "\n",
        "  completion = OpenAIclient.chat.completions.create(\n",
        "  model=\"gpt-4-0125-preview\",\n",
        "  messages=[\n",
        "  {\"role\": \"user\", \"content\": f'Your function is that of a bot optimised for summarising patent text. Answer the following query as accurately as possible based on your function {prompt}'}\n",
        "  ]\n",
        "  )\n",
        "  response = completion.choices[0].message.content\n",
        "\n",
        "  return response"
      ],
      "metadata": {
        "id": "UUiITGnU3I0W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# inputs = gradio.Textbox(lines=7, label=\"Generate Queries for use with Elastic Search, allowing for search refinement\")\n",
        "# outputs = gradio.Textbox(label=\"Reply\")\n",
        "\n",
        "# gradio.Interface(fn=DrillDown, inputs=inputs, outputs=outputs, title=\"Patent DrillDown Prototype\",\n",
        "#              theme=\"compact\").launch(share=True, debug=True)"
      ],
      "metadata": {
        "id": "s5xDQySpeTZF"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Run Testing Pipeline"
      ],
      "metadata": {
        "id": "9jaaJdkDmYOl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "query = ''\n",
        "resp = client.search(index=\"patents\",\n",
        "                     body=query)\n",
        "\n",
        "print(resp)"
      ],
      "metadata": {
        "id": "Q8hePjn5NQ4E",
        "outputId": "ec13efab-3057-4171-bb3f-9e1cd55a2022",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'took': 3, 'timed_out': False, '_shards': {'total': 1, 'successful': 1, 'skipped': 0, 'failed': 0}, 'hits': {'total': {'value': 0, 'relation': 'eq'}, 'max_score': None, 'hits': []}}\n"
          ]
        }
      ]
    }
  ]
}