{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyN3FrdpBAmSbAZfejxIICfF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/EmicoBinsfinder/EPOCodeFestProject/blob/main/TaggingTool_v1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "AwZLm-jWYBaO"
      },
      "outputs": [],
      "source": [
        "#@title Configure OpenAI API key\n",
        "\n",
        "# access your OpenAI API key\n",
        "\n",
        "# installing llmx first isn't necessary but avoids a confusing error when installing openai\n",
        "# !pip install -q llmx\n",
        "# !pip install -q openai\n",
        "from openai import OpenAI\n",
        "import google.generativeai as genai\n",
        "from google.colab import userdata\n",
        "\n",
        "\n",
        "openai_api_secret_name = 'Test'\n",
        "## @param {type: \"string\"}\n",
        "\n",
        "try:\n",
        "  OPENAI_API_KEY=userdata.get(openai_api_secret_name)\n",
        "  client = OpenAI(\n",
        "    api_key=OPENAI_API_KEY\n",
        "  )\n",
        "except userdata.SecretNotFoundError as e:\n",
        "   print(f'''Secret not found\\n\\nThis expects you to create a secret named {openai_api_secret_name} in Colab\\n\\nVisit https://platform.openai.com/api-keys to create an API key\\n\\nStore that in the secrets section on the left side of the notebook (key icon)\\n\\nName the secret {openai_api_secret_name}''')\n",
        "   raise e\n",
        "except userdata.NotebookAccessError as e:\n",
        "  print(f'''You need to grant this notebook access to the {openai_api_secret_name} secret in order for the notebook to access Gemini on your behalf.''')\n",
        "  raise e\n",
        "except Exception as e:\n",
        "  # unknown error\n",
        "  print(f\"There was an unknown error. Ensure you have a secret {openai_api_secret_name} stored in Colab and it's a valid key from https://platform.openai.com/api-keys\")\n",
        "  raise e"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## System Setup"
      ],
      "metadata": {
        "id": "VDvlToWKzTLa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# !git clone https://github.com/EmicoBinsfinder/EPOCodeFestProject.git\n",
        "# !pip install gradio"
      ],
      "metadata": {
        "id": "efCLY8SmYC9V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "#Path to embedding Model\n",
        "Model_Path = '/content/EPOCodeFestProject/TextSimilarityModel'"
      ],
      "metadata": {
        "id": "vC_VUKLF5lwI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "########## IMPORTING REQUIRED PYTHON PACKAGES ##########\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "import torch\n",
        "import math\n",
        "import time\n",
        "import csv\n",
        "import pandas as pd\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "from nltk.corpus import stopwords\n",
        "nltk.download('stopwords')\n",
        "nltk.download('punkt')\n",
        "import string\n",
        "import gradio"
      ],
      "metadata": {
        "id": "7mbvLF34rrp2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Defining embedding generation"
      ],
      "metadata": {
        "id": "n2opssXczXFA"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Format embeddings"
      ],
      "metadata": {
        "id": "c8ggBIhn0hPu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def mean_pooling(model_output, attention_mask):\n",
        "    token_embeddings = model_output[0] #First element of model_output contains all token embeddings\n",
        "    input_mask_expanded = attention_mask.unsqueeze(-1).expand(token_embeddings.size()).float()\n",
        "    return tf.reduce_sum(token_embeddings * input_mask_expanded, 1) / tf.clip_by_value(input_mask_expanded.sum(1), clip_value_min=1e-9, clip_value_max=math.inf)"
      ],
      "metadata": {
        "id": "pIhfU5Vix57o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function to embed the input text for similarity searching"
      ],
      "metadata": {
        "id": "mcZPHaSd0pch"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "### Sentence Embedder\n",
        "def sentence_embedder(sentences, model_path):\n",
        "  \"\"\"\n",
        "  Calling the sentence similarity model to generate embeddings on input text.\n",
        "  :param sentences: takes input text in the form of a string\n",
        "  :param model_path: path to the text similarity model\n",
        "  :return returns a (1, 384) embedding of the input text\n",
        "  \"\"\"\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model_path) #instantiating the sentence embedder using HuggingFace library\n",
        "  model = AutoModel.from_pretrained(model_path, from_tf=True) #making a model instance\n",
        "  encoded_input = tokenizer(sentences, padding=True, truncation=True, return_tensors='pt')\n",
        "  # Compute token embeddings\n",
        "  with torch.no_grad():\n",
        "    model_output = model(**encoded_input)\n",
        "  sentence_embeddings = mean_pooling(model_output, encoded_input['attention_mask']) #outputs a (1, 384) tensor representation of input text\n",
        "  return sentence_embeddings"
      ],
      "metadata": {
        "id": "9dAU7mzw4yhv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load Saved Embeddings"
      ],
      "metadata": {
        "id": "hTPxCNKc40RM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class_embeddings = pd.read_csv('/content/EPOCodeFestProject/MainClassEmbeddings.csv')"
      ],
      "metadata": {
        "id": "3J6PxzA7869m"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Sentence Embedding Preparation Function\n",
        "def convert_saved_embeddings(embedding_string):\n",
        "    \"\"\"\n",
        "    Preparing pre-computed embeddings for use for comparison with new abstract embeddings .\n",
        "    Pre-computed embeddings are saved as tensors in string format so need to be converted back to numpy arrays in order to calculate cosine similarity.\n",
        "    :param embedding_string:\n",
        "    :return: Should be a single tensor with dims (,384) in string formate\n",
        "    \"\"\"\n",
        "    embedding = embedding_string.replace('(', '')\n",
        "    embedding = embedding.replace(')', '')\n",
        "    embedding = embedding.replace('[', '')\n",
        "    embedding = embedding.replace(']', '')\n",
        "    embedding = embedding.replace('tensor', '')\n",
        "    embedding = embedding.replace(' ', '')\n",
        "    embedding = embedding.split(',')\n",
        "    embedding = [float(x) for x in embedding]\n",
        "    embedding = np.array(embedding)\n",
        "    embedding = np.expand_dims(embedding, axis=0)\n",
        "    embedding = torch.from_numpy(embedding)\n",
        "    return embedding"
      ],
      "metadata": {
        "id": "tO93a3K8v_if"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Clean User Input"
      ],
      "metadata": {
        "id": "WXZDBKas8Uu3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def clean_data(input, type='Dataframe'):\n",
        "    if type == 'Dataframe':\n",
        "        cleaneddf = pd.DataFrame(columns=['Class', 'Description'])\n",
        "        for i in range(0, len(input)):\n",
        "            row_list = input.loc[i, :].values.flatten().tolist()\n",
        "            noNaN_row = [x for x in row_list if str(x) != 'nan']\n",
        "            listrow = []\n",
        "            if len(noNaN_row) > 0:\n",
        "                row = noNaN_row[:-1]\n",
        "                row = [x.strip() for x in row]\n",
        "                row = (\" \").join(row)\n",
        "                text_tokens = word_tokenize(row)  # splits abstracts into individual tokens to allow removal of stopwords by list comprehension\n",
        "                Stopword_Filtered_List = [word for word in text_tokens if not word in all_stopwords]  # removes stopwords\n",
        "                row = (\" \").join(Stopword_Filtered_List)  # returns abstract to string form\n",
        "                removechars = ['[', ']', '{', '}', ';', '(', ')', ',', '.', ':', '/', '-', '#', '?', '@', 'Â£', '$']\n",
        "                for char in removechars:\n",
        "                    row = list(map(lambda x: x.replace(char, ''), row))\n",
        "\n",
        "                row = ''.join(row)\n",
        "                wnum = row.split(' ')\n",
        "                wnum = [x.lower() for x in wnum]\n",
        "                #remove duplicate words\n",
        "                wnum = list(dict.fromkeys(wnum))\n",
        "                #removing numbers\n",
        "                wonum = []\n",
        "                for x in wnum:\n",
        "                    xv = list(x)\n",
        "                    xv = [i.isnumeric() for i in xv]\n",
        "                    if True in xv:\n",
        "                        continue\n",
        "                    else:\n",
        "                        wonum.append(x)\n",
        "                row = ' '.join(wonum)\n",
        "                l = [noNaN_row[-1], row]\n",
        "                cleaneddf.loc[len(cleaneddf)] = l\n",
        "        cleaneddf = cleaneddf.drop_duplicates(subset=['Description'])\n",
        "        cleaneddf.to_csv('E:/Users/eeo21/Startup/CPC_Classifications_List/additionalcleanedclasses.csv', index=False)\n",
        "        return cleaneddf\n",
        "\n",
        "    elif type == 'String':\n",
        "        text_tokens = word_tokenize(input)  # splits abstracts into individual tokens to allow removal of stopwords by list comprehension\n",
        "        Stopword_Filtered_List = [word for word in text_tokens if not word in all_stopwords]  # removes stopwords\n",
        "        row = (\" \").join(Stopword_Filtered_List)  # returns abstract to string form\n",
        "        removechars = ['[', ']', '{', '}', ';', '(', ')', ',', '.', ':', '/', '-', '#', '?', '@', 'Â£', '$']\n",
        "        for char in removechars:\n",
        "            row = list(map(lambda x: x.replace(char, ''), row))\n",
        "        row = ''.join(row)\n",
        "        wnum = row.split(' ')\n",
        "        wnum = [x.lower() for x in wnum]\n",
        "        # remove duplicate words\n",
        "        wnum = list(dict.fromkeys(wnum))\n",
        "        # removing numbers\n",
        "        wonum = []\n",
        "        for x in wnum:\n",
        "            xv = list(x)\n",
        "            xv = [i.isnumeric() for i in xv]\n",
        "            if True in xv:\n",
        "                continue\n",
        "            else:\n",
        "                wonum.append(x)\n",
        "        row = ' '.join(wonum)\n",
        "        return row"
      ],
      "metadata": {
        "id": "Gt7Gfums8Wnh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Function for CPC Class Prediction"
      ],
      "metadata": {
        "id": "D2hTFnal5__M"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def broad_scope_class_predictor(class_embeddings, abstract_embedding, SearchType, N=5, Sensitivity='Medium'):\n",
        "    predictions = pd.DataFrame(columns=['Class Name', 'Score'])\n",
        "    for i in range(len(class_embeddings)):\n",
        "        class_name = class_embeddings.iloc[i, 0]\n",
        "        embedding = class_embeddings.iloc[i, 2]\n",
        "        embedding = convert_saved_embeddings(embedding)\n",
        "        abstract_embedding = abstract_embedding.numpy()\n",
        "        abstract_embedding = torch.from_numpy(abstract_embedding)\n",
        "        cos = torch.nn.CosineSimilarity(dim=1)\n",
        "        score = cos(abstract_embedding, embedding).numpy().tolist()\n",
        "        result = [class_name, score[0]]\n",
        "        predictions.loc[len(predictions)] = result\n",
        "\n",
        "    Threshold = 0.5\n",
        "\n",
        "    GreenLikelihood = 'False'\n",
        "    HighestSimilarity = predictions.nlargest(N, ['Score'])\n",
        "    HighestSimilarity = HighestSimilarity['Class Name'].tolist()\n",
        "    HighestSimilarityClass = [x.split('/')[0] for x in HighestSimilarity]\n",
        "\n",
        "    return HighestSimilarity\n",
        "\n",
        "def classifier(userin):\n",
        "    clean_in = clean_data(userin, type='String')\n",
        "    in_emb = sentence_embedder(clean_in, Model_Path)\n",
        "\n",
        "    Number = 10\n",
        "    broad_scope_predictions = broad_scope_class_predictor(class_embeddings, in_emb, SearchType, Number, Sensitivity='High')\n",
        "\n",
        "    return broad_scope_predictions\n",
        "\n"
      ],
      "metadata": {
        "id": "SyXfZcrB6GxJ"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Input Claim Set/Description/Abstract Here!"
      ],
      "metadata": {
        "id": "jqCMTAQD7KdF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Claims = ''\n",
        "\n",
        "Description"
      ],
      "metadata": {
        "id": "NuwAtI637RU-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Prompt Creation"
      ],
      "metadata": {
        "id": "7giOE3Tw6ziR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "Prompt = f'''Based on the description below and the patent claim set, generate a list relevant tags related to the claims where the\n",
        "tags fall into one of the following categories:\n",
        "\n",
        "1. Product:\n",
        "2. Function: What is the function of the invention\n",
        "3. Component: What components do the invention comprise\n",
        "4. Invention type: Is it for example a method claim, apparatus claim, method-of-use\n",
        "\n",
        "For each tag, also return which of the 4 categories it belongs to in the following format:\n",
        "\n",
        "{{Tag: Function}}\n",
        "\n",
        "Description:\n",
        "{Description}\n",
        "\n",
        "Claims:\n",
        "{Claims}\n",
        "'''"
      ],
      "metadata": {
        "id": "h5ns4L-UYPxj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def chatbot(input):\n",
        "  completion = client.chat.completions.create(\n",
        "  model=\"gpt-4-0125-preview\",\n",
        "  messages=[\n",
        "  {\"role\": \"user\", \"content\": '%s -- Please answer as concisely as you can, avoiding any extra conversation or text' % prompt}\n",
        "  ]\n",
        ")\n",
        "\n",
        "  response = completion.choices[0].message.content\n",
        "  return response\n",
        "\n",
        "inputs = gradio.Textbox(lines=7, label=\"Generate tags and CPC classifications based on patent claims\")\n",
        "outputs = gradio.Textbox(label=\"Reply\")\n",
        "\n",
        "gradio.Interface(fn=chatbot, inputs=inputs, outputs=outputs, title=\"Patent RAG Prototype\",\n",
        "             theme=\"compact\").launch(share=True)"
      ],
      "metadata": {
        "id": "UUiITGnU3I0W"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}